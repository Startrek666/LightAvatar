# æŠ€æœ¯å®ç°ç»†èŠ‚æ–‡æ¡£

> ğŸ“ æ·±å…¥ä»£ç çº§åˆ«çš„å®ç°ç»†èŠ‚å’Œæœ€ä½³å®è·µ

---

## ç›®å½•

1. [å…³é”®ä»£ç è§£æ](#å…³é”®ä»£ç è§£æ)
2. [è®¾è®¡æ¨¡å¼åº”ç”¨](#è®¾è®¡æ¨¡å¼åº”ç”¨)
3. [æ€§èƒ½ä¼˜åŒ–æŠ€å·§](#æ€§èƒ½ä¼˜åŒ–æŠ€å·§)
4. [å¸¸è§é—®é¢˜è§£å†³](#å¸¸è§é—®é¢˜è§£å†³)

---

## å…³é”®ä»£ç è§£æ

### 1. Session Manager ä¼šè¯ç®¡ç†

**æ–‡ä»¶**: `backend/core/session_manager.py`

#### ä¼šè¯åˆ›å»ºæµç¨‹

```python
async def create_session(self, session_id: str) -> Session:
    """åˆ›å»ºæ–°ä¼šè¯çš„å®Œæ•´æµç¨‹"""
    async with self._lock:  # 1. è·å–é”ï¼Œé˜²æ­¢å¹¶å‘é—®é¢˜
        
        # 2. æ£€æŸ¥å†…å­˜æ˜¯å¦è¶…é™
        await self.check_memory()
        
        # 3. æ£€æŸ¥ä¼šè¯æ•°é‡é™åˆ¶
        if len(self.sessions) >= settings.MAX_SESSIONS:
            # ç§»é™¤æœ€ä¹…æœªä½¿ç”¨çš„ä¼šè¯
            await self._remove_oldest_inactive()
        
        # 4. åˆ›å»ºä¼šè¯å¯¹è±¡
        session = Session(session_id=session_id)
        
        # 5. åˆå§‹åŒ–æ‰€æœ‰ Handlerï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
        await session.initialize_handlers()
        
        # 6. æ³¨å†Œåˆ°ç®¡ç†å™¨
        self.sessions[session_id] = session
        
        return session
```

**å…³é”®ç‚¹**ï¼š
- **å¼‚æ­¥é”** - é˜²æ­¢å¹¶å‘åˆ›å»ºå¯¼è‡´è¶…é™
- **å†…å­˜æ£€æŸ¥** - ä¸»åŠ¨ç®¡ç†å†…å­˜ä½¿ç”¨
- **LRU æ·˜æ±°** - ç§»é™¤æœ€ä¹…æœªä½¿ç”¨çš„ä¼šè¯
- **å»¶è¿Ÿåˆå§‹åŒ–** - éœ€è¦æ—¶æ‰åŠ è½½æ¨¡å‹

#### å†…å­˜æ§åˆ¶æœºåˆ¶

```python
async def check_memory(self):
    """ä¸‰çº§å†…å­˜æ§åˆ¶"""
    process = psutil.Process()
    memory_mb = process.memory_info().rss / 1024 / 1024
    
    # çº§åˆ«1ï¼šæ¥è¿‘ä¸Šé™ - æ¸…ç†è¿‡æœŸä¼šè¯
    if memory_mb > self.max_memory_mb * 0.8:
        logger.warning("Memory usage at 80%, cleaning up")
        await self.cleanup_old_sessions()
    
    # çº§åˆ«2ï¼šè¶…è¿‡ä¸Šé™ - å¼ºåˆ¶åƒåœ¾å›æ”¶
    if memory_mb > self.max_memory_mb:
        logger.warning("Memory exceeded, forcing GC")
        await self.cleanup_old_sessions()
        import gc
        gc.collect()
    
    # çº§åˆ«3ï¼šä¸¥é‡è¶…é™ - ç§»é™¤æ‰€æœ‰éæ´»è·ƒä¼šè¯
    if memory_mb > self.max_memory_mb * 1.2:
        logger.error("Critical memory usage!")
        # åªä¿ç•™æ­£åœ¨å¤„ç†çš„ä¼šè¯
        for session_id, session in list(self.sessions.items()):
            if not session.is_processing:
                await self.remove_session(session_id)
```

### 2. æµå¼å¤„ç†æ ¸å¿ƒå®ç°

**æ–‡ä»¶**: `backend/core/session_manager.py`

#### æµå¼æ–‡æœ¬å¤„ç†

```python
async def process_text_stream(self, text: str, callback):
    """
    æµå¼å¤„ç†çš„å…³é”®ï¼š
    1. å®æ—¶å‘é€æ–‡æœ¬ç‰‡æ®µ
    2. å¥å­çº§åˆ«è§¦å‘ TTS+Avatar
    3. å¼‚æ­¥å¹¶è¡Œå¤„ç†
    """
    
    full_response = ""
    sentence_buffer = ""
    
    # ä» LLM æµå¼è·å–å“åº”
    async for chunk in self.llm_handler.stream_response(text, history):
        full_response += chunk
        sentence_buffer += chunk
        
        # ç«‹å³å‘é€æ–‡æœ¬ç‰‡æ®µç»™å‰ç«¯
        await callback("text_chunk", {"chunk": chunk})
        
        # æ£€æµ‹å¥å­ç»“æŸ
        if self._is_sentence_end(sentence_buffer):
            # å…³é”®ï¼šä½¿ç”¨ create_task å¼‚æ­¥å¤„ç†
            # ä¸ç­‰å¾…å®Œæˆï¼Œç»§ç»­æ¥æ”¶ä¸‹ä¸€ä¸ªchunk
            asyncio.create_task(
                self._process_sentence(sentence_buffer.strip(), callback)
            )
            sentence_buffer = ""
```

**ä¸ºä»€ä¹ˆä½¿ç”¨ `create_task`ï¼Ÿ**

```python
# âŒ é”™è¯¯ï¼šåŒæ­¥ç­‰å¾…ï¼Œå¤±å»æµå¼ä¼˜åŠ¿
await self._process_sentence(sentence)  # ç­‰å¾… TTS+Avatar å®Œæˆ
# ä¸‹ä¸€ä¸ª chunk è¦ç­‰è¿™ä¸ªå¥å­å¤„ç†å®Œæ‰èƒ½å‘é€

# âœ… æ­£ç¡®ï¼šå¼‚æ­¥å¤„ç†ï¼Œç»§ç»­æ¥æ”¶ chunk
asyncio.create_task(self._process_sentence(sentence))
# ç«‹å³è¿”å›ï¼Œå¯ä»¥æ¥æ”¶ä¸‹ä¸€ä¸ª chunk
```

#### å¥å­æ£€æµ‹ç®—æ³•

```python
def _is_sentence_end(self, text: str) -> bool:
    """
    å¤šè¯­è¨€å¥å­ç»“æŸæ£€æµ‹
    
    ä¸­æ–‡ï¼šã€‚ï¼ï¼Ÿï¼›
    è‹±æ–‡ï¼š. ! ? ;
    ç‰¹æ®Šï¼šæ¢è¡Œç¬¦
    """
    if not text:
        return False
    
    delimiters = ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?', 'ï¼›', ';', '\n']
    
    # è€ƒè™‘å¼•å·å†…çš„æ ‡ç‚¹
    text_stripped = text.rstrip()
    
    # é¿å…è¯¯åˆ¤ï¼ˆå¦‚ï¼š3.14ã€Mr.ï¼‰
    if text_stripped.endswith('.'):
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°å­—å°æ•°ç‚¹
        if len(text_stripped) > 1 and text_stripped[-2].isdigit():
            return False
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç¼©å†™
        words = text_stripped.split()
        if words and len(words[-1]) <= 3:  # å¦‚ Mr. Dr.
            return False
    
    return any(text_stripped.endswith(d) for d in delimiters)
```

### 3. Wav2Lip ONNX æ¨ç†

**æ–‡ä»¶**: `backend/handlers/avatar/wav2lip_handler.py`

#### Mel Spectrogram æå–

```python
async def _extract_mel_chunks(self, audio_data: bytes) -> List[np.ndarray]:
    """
    ä»éŸ³é¢‘æå– Mel é¢‘è°±å›¾
    
    å‚æ•°è§£é‡Šï¼š
    - n_fft=800: FFT çª—å£å¤§å°ï¼ˆ50ms @ 16kHzï¼‰
    - hop_length=200: è·³è·ƒé•¿åº¦ï¼ˆ12.5ms @ 16kHzï¼‰
    - n_mels=80: Mel é¢‘å¸¦æ•°é‡
    """
    
    # 1. è½¬æ¢ä¸ºéŸ³é¢‘æ•°ç»„
    audio_io = io.BytesIO(audio_data)
    audio, sr = sf.read(audio_io)
    
    # 2. é‡é‡‡æ ·åˆ° 16kHz
    if sr != 16000:
        audio = librosa.resample(audio, orig_sr=sr, target_sr=16000)
    
    # 3. æå– Mel é¢‘è°±
    mel = librosa.feature.melspectrogram(
        y=audio,
        sr=16000,
        n_fft=800,
        hop_length=200,
        n_mels=80,
        fmin=55,    # æœ€ä½é¢‘ç‡ï¼ˆäººå£°èŒƒå›´ï¼‰
        fmax=7600   # æœ€é«˜é¢‘ç‡
    )
    
    # 4. è½¬æ¢ä¸ºå¯¹æ•°åˆ»åº¦
    mel_db = librosa.power_to_db(mel, ref=np.max)
    
    # 5. å½’ä¸€åŒ–åˆ° [0, 1]
    mel_normalized = (mel_db - mel_db.min()) / (mel_db.max() - mel_db.min() + 1e-8)
    
    # 6. åˆ‡åˆ†ä¸ºå›ºå®šé•¿åº¦çš„ chunk
    mel_chunks = []
    for i in range(0, mel_normalized.shape[1] - 16 + 1, 16):
        chunk = mel_normalized[:, i:i+16]  # (80, 16)
        mel_chunks.append(chunk.astype(np.float32))
    
    return mel_chunks
```

**ä¸ºä»€ä¹ˆè¿™äº›å‚æ•°ï¼Ÿ**

```
n_mels=80:
- Wav2Lip è®ºæ–‡ä¸­ä½¿ç”¨çš„æ ‡å‡†
- è¶³å¤Ÿæ•æ‰è¯­éŸ³ç‰¹å¾
- è®¡ç®—é‡é€‚ä¸­

n_fft=800 (50ms):
- å¹³è¡¡æ—¶é—´å’Œé¢‘ç‡åˆ†è¾¨ç‡
- é€‚åˆè¯­éŸ³åˆ†æ

hop_length=200 (12.5ms):
- 25fps è§†é¢‘å¯¹åº” 40ms/å¸§
- 12.5ms æä¾›è¶³å¤Ÿçš„æ—¶é—´åˆ†è¾¨ç‡
```

#### äººè„¸æ£€æµ‹ä¸è£å‰ª

```python
def _detect_face(self, image: np.ndarray) -> Optional[Tuple[int, int, int, int]]:
    """
    ä½¿ç”¨ MediaPipe æ£€æµ‹äººè„¸
    
    è¿”å›ï¼š(x, y, width, height)
    """
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = self.face_detector.process(rgb_image)
    
    if results.detections:
        detection = results.detections[0]
        bbox = detection.location_data.relative_bounding_box
        
        # è½¬æ¢ä¸ºåƒç´ åæ ‡
        h, w = image.shape[:2]
        x = int(bbox.xmin * w)
        y = int(bbox.ymin * h)
        width = int(bbox.width * w)
        height = int(bbox.height * h)
        
        # æ·»åŠ  paddingï¼ˆå…³é”®ï¼šç»™å˜´å”‡ç•™å‡ºç©ºé—´ï¼‰
        padding = 20
        x = max(0, x - padding)
        y = max(0, y - padding)
        width = min(w - x, width + 2 * padding)
        height = min(h - y, height + 2 * padding)
        
        return (x, y, width, height)
    
    return None
```

#### ONNX æ¨ç†æµç¨‹

```python
def _process_batch(self, frames: List[np.ndarray], mel_chunks: List[np.ndarray]):
    """
    æ‰¹é‡å¤„ç†å¸§
    
    è¾“å…¥ï¼š
    - frames: åŸå§‹è§†é¢‘å¸§ (H, W, 3)
    - mel_chunks: Mel é¢‘è°± (80, 16)
    
    è¾“å‡ºï¼š
    - å˜´å‹åŒæ­¥åçš„å¸§
    """
    output_frames = []
    
    for frame, mel in zip(frames, mel_chunks):
        # 1. æ£€æµ‹äººè„¸
        face_coords = self._detect_face(frame)
        if not face_coords:
            output_frames.append(frame)
            continue
        
        # 2. è£å‰ªäººè„¸åŒºåŸŸ
        face_img = self._crop_face(frame, face_coords)  # â†’ (96, 96, 3)
        
        # 3. é¢„å¤„ç†
        face_input = self._preprocess_face(face_img)  # â†’ (1, 1, 3, 96, 96)
        mel_input = mel.reshape(1, 1, 80, 16)
        
        # 4. ONNX æ¨ç†
        outputs = self.wav2lip_session.run(
            None,  # æ‰€æœ‰è¾“å‡º
            {
                'audio': mel_input.astype(np.float32),
                'face': face_input.astype(np.float32)
            }
        )
        
        # 5. åå¤„ç†
        lip_img = self._postprocess_output(outputs[0])  # â†’ (96, 96, 3)
        
        # 6. èåˆå›åŸå›¾
        output_frame = self._merge_face(frame, lip_img, face_coords)
        output_frames.append(output_frame)
    
    return output_frames
```

### 4. FFmpeg è§†é¢‘ç¼–ç 

**æ–‡ä»¶**: `backend/utils/video_utils.py`

#### H.264 ç¼–ç å‚æ•°è¯¦è§£

```python
ffmpeg_cmd = [
    'ffmpeg',
    '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
    
    # === è¾“å…¥é…ç½® ===
    '-f', 'rawvideo',         # æ ¼å¼ï¼šåŸå§‹è§†é¢‘
    '-vcodec', 'rawvideo',    # ç¼–è§£ç å™¨
    '-s', '512x512',          # åˆ†è¾¨ç‡
    '-pix_fmt', 'bgr24',      # OpenCV çš„åƒç´ æ ¼å¼
    '-r', '25',               # å¸§ç‡
    '-i', '-',                # ä» stdin è¯»å–
    
    # === ç¼–ç é…ç½® ===
    '-c:v', 'libx264',        # H.264 ç¼–ç å™¨
    '-preset', 'ultrafast',   # é€Ÿåº¦ä¼˜å…ˆï¼ˆ9ä¸ªçº§åˆ«ï¼‰
    '-tune', 'zerolatency',   # é›¶å»¶è¿Ÿè°ƒä¼˜
    '-crf', '23',             # è´¨é‡å› å­ï¼ˆ0-51ï¼Œè¶Šå°è¶Šå¥½ï¼‰
    
    # === è¾“å‡ºé…ç½® ===
    '-pix_fmt', 'yuv420p',    # å…¼å®¹æ€§æœ€å¥½çš„æ ¼å¼
    '-movflags', '+faststart', # æµå¼å‹å¥½ï¼ˆmoov atom å‰ç½®ï¼‰
    
    '-f', 'mp4',              # è¾“å‡ºæ ¼å¼
    'pipe:1'                  # è¾“å‡ºåˆ° stdout
]
```

**å‚æ•°é€‰æ‹©ä¾æ®**ï¼š

```
preset é€‰é¡¹ï¼š
- ultrafast: æœ€å¿«ï¼Œå‹ç¼©ç‡æœ€ä½
- superfast
- veryfast
- faster
- fast
- medium (é»˜è®¤)
- slow
- slower
- veryslow: æœ€æ…¢ï¼Œå‹ç¼©ç‡æœ€é«˜

æœ¬é¡¹ç›®é€‰æ‹© ultrafast å› ä¸ºï¼š
âœ“ å®æ—¶æ€§è¦æ±‚é«˜
âœ“ CPU æ€§èƒ½æœ‰é™
âœ“ ç½‘ç»œå¸¦å®½å……è¶³
âœ— ä¸éœ€è¦æè‡´å‹ç¼©

CRF å€¼ï¼š
- 0: æ— æŸï¼ˆæ–‡ä»¶å·¨å¤§ï¼‰
- 18: è§†è§‰æ— æŸ
- 23: é»˜è®¤ï¼ˆè´¨é‡ä¸ä½“ç§¯å¹³è¡¡ï¼‰
- 28: ä¸­ç­‰è´¨é‡
- 51: æœ€å·®è´¨é‡

æœ¬é¡¹ç›®é€‰æ‹© 23 å› ä¸ºï¼š
âœ“ è´¨é‡è¶³å¤Ÿå¥½
âœ“ ä½“ç§¯é€‚ä¸­
âœ“ ç¼–ç é€Ÿåº¦å¿«

faststart:
- å°† moov atom ç§»åˆ°æ–‡ä»¶å¼€å¤´
- æ”¯æŒè¾¹ä¸‹è½½è¾¹æ’­æ”¾
- å¯¹æµå¼ä¼ è¾“è‡³å…³é‡è¦
```

### 5. WebSocket ç®¡ç†

**æ–‡ä»¶**: `backend/app/websocket.py`

#### è¿æ¥ç®¡ç†

```python
class WebSocketManager:
    def __init__(self):
        # è¿æ¥å­—å…¸ï¼šsession_id â†’ WebSocket
        self.active_connections: Dict[str, WebSocket] = {}
        
        # ä»»åŠ¡å­—å…¸ï¼šsession_id â†’ Taskï¼ˆå¿ƒè·³ç­‰ï¼‰
        self.connection_tasks: Dict[str, asyncio.Task] = {}
    
    async def connect(self, websocket: WebSocket, session_id: str):
        """æ¥å—å¹¶æ³¨å†Œæ–°è¿æ¥"""
        await websocket.accept()
        self.active_connections[session_id] = websocket
        logger.info(f"WebSocket connected: {session_id}")
    
    def disconnect(self, session_id: str):
        """æ–­å¼€å¹¶æ¸…ç†è¿æ¥"""
        if session_id in self.active_connections:
            del self.active_connections[session_id]
        
        # å–æ¶ˆç›¸å…³ä»»åŠ¡
        if session_id in self.connection_tasks:
            self.connection_tasks[session_id].cancel()
            del self.connection_tasks[session_id]
```

#### å¿ƒè·³æœºåˆ¶

```python
async def heartbeat(self, session_id: str, interval: int = 30):
    """
    å®šæœŸå‘é€å¿ƒè·³ï¼Œä¿æŒè¿æ¥æ´»è·ƒ
    
    ä¸ºä»€ä¹ˆéœ€è¦å¿ƒè·³ï¼Ÿ
    1. æ£€æµ‹è¿æ¥æ˜¯å¦æ–­å¼€
    2. é˜²æ­¢ Nginx è¶…æ—¶æ–­å¼€
    3. ä¿æŒ NAT æ˜ å°„
    """
    while self.is_connected(session_id):
        try:
            await self.send_json(session_id, {"type": "heartbeat"})
            await asyncio.sleep(interval)
        except Exception as e:
            logger.error(f"Heartbeat failed: {e}")
            break
    
    # å¿ƒè·³å¤±è´¥ï¼Œæ¸…ç†è¿æ¥
    self.disconnect(session_id)
```

---

## è®¾è®¡æ¨¡å¼åº”ç”¨

### 1. Handler æ¨¡å¼ï¼ˆç­–ç•¥æ¨¡å¼å˜ä½“ï¼‰

**é—®é¢˜**ï¼šä¸åŒçš„ AI æ¨¡å‹æœ‰ä¸åŒçš„åˆå§‹åŒ–ã€å¤„ç†é€»è¾‘

**è§£å†³**ï¼šå®šä¹‰ç»Ÿä¸€æ¥å£ï¼Œå°è£…å˜åŒ–

```python
# åŸºç±»å®šä¹‰æ¥å£
class BaseHandler(ABC):
    @abstractmethod
    async def _setup(self):
        pass
    
    @abstractmethod
    async def process(self, data: Any) -> Any:
        pass

# å…·ä½“å®ç°
class WhisperHandler(BaseHandler):
    async def _setup(self):
        self.model = WhisperModel(...)
    
    async def process(self, audio: bytes) -> str:
        return await self._transcribe(audio)

class EdgeTTSHandler(BaseHandler):
    async def _setup(self):
        # Edge TTS æ— éœ€åˆå§‹åŒ–
        pass
    
    async def process(self, text: str) -> bytes:
        return await self._synthesize(text)
```

**ä¼˜åŠ¿**ï¼š
- ç»Ÿä¸€æ¥å£ï¼Œæ˜“äºæ›¿æ¢
- æ˜“äºæµ‹è¯•ï¼ˆMock Handlerï¼‰
- æ˜“äºæ‰©å±•ï¼ˆæ–°å¢ Handlerï¼‰

### 2. Session æ¨¡å¼ï¼ˆä¼šè¯çŠ¶æ€ç®¡ç†ï¼‰

**é—®é¢˜**ï¼šå¤šç”¨æˆ·å¹¶å‘ï¼ŒçŠ¶æ€éš”ç¦»

**è§£å†³**ï¼šæ¯ä¸ªç”¨æˆ·ç‹¬ç«‹çš„ Session å¯¹è±¡

```python
@dataclass
class Session:
    session_id: str
    created_at: datetime
    
    # æ¯ä¸ªä¼šè¯ç‹¬ç«‹çš„ Handler
    vad_handler: Optional[SileroVADHandler]
    asr_handler: Optional[WhisperHandler]
    llm_handler: Optional[OpenAIHandler]
    
    # ç‹¬ç«‹çš„çŠ¶æ€
    conversation_history: List[dict]
    audio_buffer: List[bytes]
    is_processing: bool
```

### 3. Manager æ¨¡å¼ï¼ˆèµ„æºç®¡ç†ï¼‰

**é—®é¢˜**ï¼šSession ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€èµ„æºé™åˆ¶

**è§£å†³**ï¼šSessionManager ç»Ÿä¸€ç®¡ç†

```python
class SessionManager:
    def __init__(self, max_memory_mb: int):
        self.sessions: Dict[str, Session] = {}
        self.max_memory_mb = max_memory_mb
    
    async def create_session(self, session_id: str) -> Session:
        # æ£€æŸ¥èµ„æºé™åˆ¶
        await self.check_memory()
        
        # åˆ›å»ºå¹¶ç®¡ç† Session
        session = Session(session_id)
        self.sessions[session_id] = session
        return session
```

### 4. Callback æ¨¡å¼ï¼ˆæµå¼å›è°ƒï¼‰

**é—®é¢˜**ï¼šæµå¼æ•°æ®éœ€è¦å®æ—¶å‘é€ç»™å®¢æˆ·ç«¯

**è§£å†³**ï¼šé€šè¿‡å›è°ƒå‡½æ•°è§£è€¦

```python
async def process_text_stream(self, text: str, callback):
    """
    callback ç­¾åï¼š
    async def callback(chunk_type: str, data: dict)
    """
    async for chunk in llm.stream():
        # é€šè¿‡å›è°ƒå‘é€æ•°æ®
        await callback("text_chunk", {"chunk": chunk})
```

### 5. å·¥å‚æ¨¡å¼ï¼ˆæ¨¡å‹åŠ è½½ï¼‰

**é—®é¢˜**ï¼šä¸åŒæ¨¡å‹åŠ è½½æ–¹å¼ä¸åŒ

**è§£å†³**ï¼šå·¥å‚æ–¹æ³•åˆ›å»º Handler

```python
class HandlerFactory:
    @staticmethod
    def create_asr_handler(model_type: str):
        if model_type == "whisper":
            return WhisperHandler()
        elif model_type == "vosk":
            return VoskHandler()
        else:
            raise ValueError(f"Unknown ASR: {model_type}")
```

---

## æ€§èƒ½ä¼˜åŒ–æŠ€å·§

### 1. å»¶è¿Ÿåˆå§‹åŒ–ï¼ˆLazy Loadingï¼‰

```python
class Session:
    async def process_text(self, text: str):
        # ä»…åœ¨éœ€è¦æ—¶åˆå§‹åŒ–
        if not self.llm_handler:
            self.llm_handler = OpenAIHandler()
            await self.llm_handler.initialize()
        
        return await self.llm_handler.process(text)
```

### 2. å¯¹è±¡æ± ï¼ˆObject Poolï¼‰

```python
class ModelPool:
    def __init__(self, model_class, pool_size=3):
        self.pool = [model_class() for _ in range(pool_size)]
        self.available = asyncio.Queue()
        for model in self.pool:
            self.available.put_nowait(model)
    
    async def acquire(self):
        return await self.available.get()
    
    def release(self, model):
        self.available.put_nowait(model)

# ä½¿ç”¨
async with model_pool.acquire() as model:
    result = await model.process(data)
```

### 3. æ‰¹å¤„ç†ï¼ˆBatchingï¼‰

```python
async def process_frames_batch(frames: List[np.ndarray]):
    """æ‰¹é‡å¤„ç†å‡å°‘æ¨ç†æ¬¡æ•°"""
    batch_size = 8
    results = []
    
    for i in range(0, len(frames), batch_size):
        batch = frames[i:i+batch_size]
        # ONNX æ”¯æŒæ‰¹é‡æ¨ç†
        batch_results = onnx_session.run(None, {
            'input': np.stack(batch)  # (batch_size, ...)
        })
        results.extend(batch_results)
    
    return results
```

### 4. ç¼“å­˜ï¼ˆCachingï¼‰

```python
from functools import lru_cache

@lru_cache(maxsize=128)
def preprocess_audio(audio_hash: str):
    """ç¼“å­˜é¢„å¤„ç†ç»“æœ"""
    return expensive_preprocessing(audio_hash)

# ä½¿ç”¨
audio_hash = hashlib.md5(audio_bytes).hexdigest()
processed = preprocess_audio(audio_hash)
```

### 5. å¼‚æ­¥I/O

```python
# âŒ åŒæ­¥ï¼šé˜»å¡
def read_file(path):
    with open(path, 'r') as f:
        return f.read()

# âœ… å¼‚æ­¥ï¼šéé˜»å¡
import aiofiles

async def read_file(path):
    async with aiofiles.open(path, 'r') as f:
        return await f.read()
```

---

## å¸¸è§é—®é¢˜è§£å†³

### 1. å†…å­˜æ³„æ¼

**ç—‡çŠ¶**ï¼šå†…å­˜æŒç»­å¢é•¿

**æ’æŸ¥**ï¼š
```python
import tracemalloc

tracemalloc.start()

# è¿è¡Œä»£ç 
...

snapshot = tracemalloc.take_snapshot()
top_stats = snapshot.statistics('lineno')

for stat in top_stats[:10]:
    print(stat)
```

**å¸¸è§åŸå› **ï¼š
1. å¾ªç¯å¼•ç”¨
2. æœªæ¸…ç†çš„å¤§å¯¹è±¡
3. ç¼“å­˜æ— é™å¢é•¿

**è§£å†³**ï¼š
```python
# ä½¿ç”¨å¼±å¼•ç”¨
import weakref
self.cache = weakref.WeakValueDictionary()

# é™åˆ¶ç¼“å­˜å¤§å°
from functools import lru_cache
@lru_cache(maxsize=128)

# æ‰‹åŠ¨æ¸…ç†
def cleanup(self):
    self.large_object = None
    gc.collect()
```

### 2. å¹¶å‘é—®é¢˜

**ç—‡çŠ¶**ï¼šå¶ç°é”™è¯¯ã€æ•°æ®ä¸ä¸€è‡´

**æ’æŸ¥**ï¼š
```python
import threading
print(f"Thread: {threading.current_thread().name}")
print(f"Task: {asyncio.current_task()}")
```

**è§£å†³**ï¼š
```python
# ä½¿ç”¨é”
self._lock = asyncio.Lock()

async with self._lock:
    # ä¸´ç•ŒåŒºä»£ç 
    self.shared_state += 1
```

### 3. æ­»é”

**ç—‡çŠ¶**ï¼šç¨‹åºå¡ä½

**æ’æŸ¥**ï¼š
```python
# å¯ç”¨ asyncio debug æ¨¡å¼
asyncio.run(main(), debug=True)

# æ£€æŸ¥ Task çŠ¶æ€
for task in asyncio.all_tasks():
    print(task.get_stack())
```

**é¿å…**ï¼š
```python
# è®¾ç½®è¶…æ—¶
try:
    await asyncio.wait_for(operation(), timeout=10.0)
except asyncio.TimeoutError:
    logger.error("Operation timeout")
```

### 4. ONNX æ¨ç†é”™è¯¯

**å¸¸è§é”™è¯¯**ï¼š
```
Error: Tensor shape mismatch
```

**æ’æŸ¥**ï¼š
```python
# æ‰“å°è¾“å…¥å½¢çŠ¶
print(f"Face input shape: {face_input.shape}")
print(f"Expected: (1, 1, 3, 96, 96)")

# æ£€æŸ¥æ•°æ®ç±»å‹
print(f"Face dtype: {face_input.dtype}")
print(f"Expected: float32")
```

**è§£å†³**ï¼š
```python
# ç¡®ä¿å½¢çŠ¶æ­£ç¡®
face_input = face_input.reshape(1, 1, 3, 96, 96)

# ç¡®ä¿ç±»å‹æ­£ç¡®
face_input = face_input.astype(np.float32)

# æ£€æŸ¥æ•°å€¼èŒƒå›´
assert face_input.min() >= -1 and face_input.max() <= 1
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0.0  
**æœ€åæ›´æ–°**: 2024-10-16

