import { ref } from 'vue'

export function useAudioRecorder() {
    const isRecording = ref(false)
    const stream = ref<MediaStream | null>(null)
    const shouldSendData = ref(true)  // æ§åˆ¶æ˜¯å¦å‘é€æ•°æ®
    const audioContext = ref<AudioContext | null>(null)
    const processor = ref<ScriptProcessorNode | null>(null)

    const startRecording = async (onDataAvailable?: (data: ArrayBuffer) => void) => {
        try {
            // Request microphone access with specific constraints
            stream.value = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    channelCount: 1,  // å•å£°é“
                    sampleRate: 16000,  // 16kHz
                    echoCancellation: true,
                    noiseSuppression: true
                } 
            })

            console.log('ğŸ¤ ä½¿ç”¨ AudioContext å½•åˆ¶ PCM æ ¼å¼')
            
            // ä½¿ç”¨ AudioContext å¤„ç†éŸ³é¢‘ä¸º PCM æ ¼å¼
            audioContext.value = new AudioContext({ sampleRate: 16000 })
            const source = audioContext.value.createMediaStreamSource(stream.value)
            
            // åˆ›å»ºéŸ³é¢‘å¤„ç†å™¨ï¼ˆ4096 æ˜¯ç¼“å†²åŒºå¤§å°ï¼‰
            processor.value = audioContext.value.createScriptProcessor(4096, 1, 1)

            // é‡ç½®å‘é€æ ‡å¿—
            shouldSendData.value = true

            // å¤„ç†éŸ³é¢‘æ•°æ®
            processor.value.onaudioprocess = (e: AudioProcessingEvent) => {
                if (!shouldSendData.value) return
                
                // è·å–éŸ³é¢‘æ•°æ®ï¼ˆFloat32Arrayï¼‰
                const inputData = e.inputBuffer.getChannelData(0)
                
                // è½¬æ¢ä¸º Int16Array (PCM 16-bit)
                const pcmData = new Int16Array(inputData.length)
                for (let i = 0; i < inputData.length; i++) {
                    // å°† -1.0 åˆ° 1.0 çš„æµ®ç‚¹æ•°è½¬æ¢ä¸º -32768 åˆ° 32767 çš„æ•´æ•°
                    const s = Math.max(-1, Math.min(1, inputData[i]))
                    pcmData[i] = s < 0 ? s * 0x8000 : s * 0x7FFF
                }
                
                // å‘é€ PCM æ•°æ®
                if (onDataAvailable) {
                    onDataAvailable(pcmData.buffer)
                }
            }
            
            // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
            source.connect(processor.value)
            processor.value.connect(audioContext.value.destination)
            
            isRecording.value = true
            console.log('âœ… PCM å½•éŸ³å™¨å·²å¯åŠ¨')

        } catch (error) {
            console.error('Failed to start recording:', error)
            throw error
        }
    }

    const stopRecording = () => {
        if (isRecording.value) {
            // ç«‹å³ç¦ç”¨æ•°æ®å‘é€
            shouldSendData.value = false
            console.log('ğŸ›‘ ç¦ç”¨æ•°æ®å‘é€')
            
            // æ–­å¼€éŸ³é¢‘èŠ‚ç‚¹
            if (processor.value) {
                processor.value.disconnect()
                processor.value.onaudioprocess = null
                processor.value = null
            }
            
            // å…³é—­ AudioContext
            if (audioContext.value) {
                audioContext.value.close()
                audioContext.value = null
            }
            
            isRecording.value = false

            // Stop all tracks
            if (stream.value) {
                stream.value.getTracks().forEach(track => track.stop())
                stream.value = null
            }
            
            console.log('ğŸ›‘ PCM å½•éŸ³å™¨å·²å®Œå…¨åœæ­¢')
        }
    }

    return {
        isRecording,
        startRecording,
        stopRecording
    }
}
