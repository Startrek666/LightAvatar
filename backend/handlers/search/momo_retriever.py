"""
Momo Search Retriever - æ–‡æ¡£æ£€ç´¢å’Œå¤„ç†
"""
from typing import List

from langchain_text_splitters import RecursiveCharacterTextSplitter
from loguru import logger

from .momo_utils import SearchDocument


def expand_docs_by_text_split(docs: List[SearchDocument]) -> List[SearchDocument]:
    """
    å°†æ–‡æ¡£å±•å¼€ä¸ºå¤šä¸ªå°å—
    
    Args:
        docs: åŽŸå§‹æ–‡æ¡£åˆ—è¡¨
    
    Returns:
        å±•å¼€åŽçš„æ–‡æ¡£åˆ—è¡¨
    """
    res_docs = []
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,  # å—å¤§å°ï¼ˆå­—ç¬¦ï¼‰
        chunk_overlap=50,  # å—é‡å ï¼ˆå­—ç¬¦ï¼‰
        add_start_index=True,  # è·Ÿè¸ªåŽŸå§‹æ–‡æ¡£ä¸­çš„ç´¢å¼•
    )
    
    for doc in docs:
        if doc.content and len(doc.content) > 100:
            all_splits = text_splitter.split_text(doc.content)
            logger.debug(f"ðŸ“„ æ–‡æ¡£ '{doc.title[:30]}...' åˆ†å—: {len(all_splits)}å—")
            
            for split in all_splits:
                res_docs.append(SearchDocument(
                    title=doc.title,
                    url=doc.url,
                    snippet=doc.snippet,
                    content=split,
                ))
        else:
            res_docs.append(doc)
    
    logger.info(f"âœ‚ï¸ æ–‡æ¡£åˆ†å—å®Œæˆ: {len(docs)} -> {len(res_docs)} å—")
    return res_docs


def merge_docs_by_url(docs: List[SearchDocument]) -> List[SearchDocument]:
    """
    æŒ‰URLåˆå¹¶æ–‡æ¡£ï¼Œå°†åŒä¸€URLçš„å¤šä¸ªå—åˆå¹¶
    
    Args:
        docs: æ–‡æ¡£åˆ—è¡¨
    
    Returns:
        åˆå¹¶åŽçš„æ–‡æ¡£åˆ—è¡¨
    """
    url_to_docs = {}
    
    # æŒ‰URLåˆ†ç»„
    for doc in docs:
        if doc.url not in url_to_docs:
            url_to_docs[doc.url] = []
        url_to_docs[doc.url].append(doc)
    
    merged_docs = []
    
    # åˆå¹¶åŒä¸€URLçš„æ–‡æ¡£
    for url, doc_list in url_to_docs.items():
        if len(doc_list) == 1:
            # åªæœ‰ä¸€ä¸ªæ–‡æ¡£ï¼Œæ— éœ€åˆå¹¶
            merged_docs.append(doc_list[0])
        else:
            # åˆå¹¶å¤šä¸ªæ–‡æ¡£
            base_doc = doc_list[0]
            
            # åˆå¹¶å†…å®¹
            combined_content = "\n".join([d.content for d in doc_list if d.content])
            
            merged_doc = SearchDocument(
                title=base_doc.title,
                url=base_doc.url,
                snippet=base_doc.snippet,
                content=combined_content,
                score=max(d.score for d in doc_list)  # å–æœ€é«˜åˆ†
            )
            
            merged_docs.append(merged_doc)
            logger.debug(f"ðŸ”— åˆå¹¶URL '{url[:50]}...': {len(doc_list)}å— -> 1å—")
    
    logger.info(f"ðŸ”— æ–‡æ¡£åˆå¹¶å®Œæˆ: {len(docs)} -> {len(merged_docs)} ä¸ªURL")
    return merged_docs



